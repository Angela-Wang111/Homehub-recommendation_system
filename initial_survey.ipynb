{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses code from https://ariepratama.github.io/How-to-do-conjoint-analysis-in-python/ verbatim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need data on whether the user is \"interested\" in a property or not, instead of user rating.\n",
    "This makes it less burdensome for users to fill out the survey, enabling us to show more listings to users for better accuracy.\n",
    "\n",
    "Price data is used as categorical data, not numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 1'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#ch0000000untitled?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#ch0000000untitled?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#ch0000000untitled?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mstatsmodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msm\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('bmh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "\n",
    "# create mock data for demo purpose\n",
    "room_count = [2, 2, 1, 3, 1] # bedroom count\n",
    "rent = [2400, 2600, 2100, 3200, 2000] # USD per month per apartment\n",
    "distance_min = [4, 3, 5, 2, 20] # minute drive\n",
    "direct_bus = [0, 1, 1, 0, 1] # whether the apartment has a direct bus route to campus\n",
    "user_rating = [8, 7, 3, 10, 1] # 1 to 10 rating from user\n",
    "interested = [1, 1, 0, 1, 0] # whether user is interested in the property\n",
    "\n",
    "\n",
    "matrix = np.matrix([room_count, rent, distance_min, direct_bus, user_rating, interested]).T\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    data=matrix,\n",
    "    columns = ['room_count', 'rent', 'distance', 'direct_bus', 'user_rating', 'interested'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check missing data\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty rows\n",
    "clean_df = df[~df['user_rating'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecte data for choice-based conjoint analysis\n",
    "y = clean_df['interested']\n",
    "x = clean_df.drop(['user_rating', 'interested'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xdum = pd.get_dummies(x, columns=x.columns)\n",
    "xdum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = sm.OLS(y, xdum, family=sm.families.Binomial()).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to assemble per attribute for every level of that attribute in dicionary\n",
    "range_per_feature = dict()\n",
    "for key, coeff in res.params.items():\n",
    "    sk = key.split('_')\n",
    "    feature = sk[0]\n",
    "    if len(sk) == 1:\n",
    "        feature = key\n",
    "    if feature not in range_per_feature:\n",
    "        range_per_feature[feature] = list()\n",
    "        \n",
    "    range_per_feature[feature].append(coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importance per feature is range of coef in a feature\n",
    "# while range is simply max(x) - min(x)\n",
    "importance_per_feature = {\n",
    "    k: max(v) - min(v) for k, v in range_per_feature.items()\n",
    "}\n",
    "\n",
    "# compute relative importance per feature\n",
    "# or normalized feature importance by dividing \n",
    "# sum of importance for all features\n",
    "total_feature_importance = sum(importance_per_feature.values())\n",
    "relative_importance_per_feature = {\n",
    "    k: 100 * round(v/total_feature_importance, 3) for k, v in importance_per_feature.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_data = pd.DataFrame(\n",
    "    list(relative_importance_per_feature.items()), \n",
    "    columns=['attr', 'relative_importance (pct)']\n",
    ").sort_values(by='relative_importance (pct)', ascending=False)\n",
    "\n",
    "\n",
    "f, ax = plt.subplots(figsize=(12, 8))\n",
    "xbar = np.arange(len(alt_data['attr']))\n",
    "plt.title('Relative importance / Normalized importance')\n",
    "plt.barh(xbar, alt_data['relative_importance (pct)'])\n",
    "for i, v in enumerate(alt_data['relative_importance (pct)']):\n",
    "    ax.text(v , i + .25, '{:.2f}%'.format(v))\n",
    "plt.ylabel('attributes')\n",
    "plt.xlabel('% relative importance')\n",
    "plt.yticks(xbar, alt_data['attr'])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9c66f17f95cc70ef61b35eb1e4b30b75128f9b46da7eb6a212ee5f9346a542bd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('data-science')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
